{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State tomography\n",
    "State tomography involves measuring a quantum state repeatedly in the bases given by `itertools.product(['X', 'Y', 'Z], repeat=n_qubits)`. From these measurements, we can reconstruct a density matrix $\\rho$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyquil import Program, get_qc\n",
    "from pyquil.gates import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a state with a `Program`\n",
    "We'll construct a two-qubit graph state by Hadamarding all qubits and then applying a controlled-Z operation across edges of our graph. In the two-qubit case, there's only one edge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits = [0, 1]\n",
    "program = Program()\n",
    "for qubit in qubits:\n",
    "    program += H(qubit)\n",
    "program += CZ(qubits[0], qubits[1])\n",
    "print(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a `TomographyExperiment` for state tomography\n",
    "We can print this out to see the 16 measurements we will perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_qcvv.tomography import generate_state_tomography_experiment\n",
    "experiment = generate_state_tomography_experiment(program=program, qubits=qubits)\n",
    "print(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional grouping\n",
    "We can simultaneously estimate some of these observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquil.operator_estimation import group_experiments\n",
    "print(group_experiments(experiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyQuil will run the tomography programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquil.operator_estimation import measure_observables\n",
    "\n",
    "qc = get_qc('2q-pyqvm')\n",
    "from forest_qcvv.compilation import basic_compile\n",
    "qc.compiler.quil_to_native_quil = basic_compile\n",
    "\n",
    "results = list(measure_observables(qc=qc, tomo_experiment=experiment, n_shots=100_000))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half-way between conversion\n",
    "from forest_qcvv.tomography import shim_pyquil_results_to_TomographyData\n",
    "data = shim_pyquil_results_to_TomographyData(program=program, qubits=qubits, counts=100_000, results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can look at a bunch of numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_qcvv.tomography import linear_inv_state_estimate\n",
    "rho = linear_inv_state_estimate(data).estimate.state_point_est\n",
    "rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = (1/2) * np.array([1, 1, 1, -1])\n",
    "rho_true = np.outer(psi, psi.T.conj())\n",
    "rho_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or visualize using Hinton plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from forest_qcvv.plotting import hinton\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "hinton(rho_true, ax=ax1)\n",
    "hinton(rho, ax=ax2)\n",
    "ax1.set_title('Analytical')\n",
    "ax2.set_title('Estimated')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix norm between true and estimated is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(rho - rho_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear inversion estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_qcvv.tomography import linear_inv_state_estimate\n",
    "rho = linear_inv_state_estimate(data).estimate.state_point_est\n",
    "\n",
    "print(np.round(rho, 4))\n",
    "print('Purity =', np.trace(rho @ rho))\n",
    "hinton(rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Liklihood Estimate (MLE) via diluted iterative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_qcvv.tomography import iterative_mle_state_estimate\n",
    "est_mle, status = iterative_mle_state_estimate(data, dilution=0.5)\n",
    "rho = est_mle.estimate.state_point_est\n",
    "print(np.around(rho, decimals=4))\n",
    "print('Purity =', np.trace(rho @ rho))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE with Max Entropy constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_max_ent, stat = iterative_mle_state_estimate(data, dilution=0.5, entropy_penalty=0.005)\n",
    "rho = est_max_ent.estimate.state_point_est\n",
    "print(np.around(rho, decimals=4))\n",
    "print('Purity =', np.trace(rho @ rho))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE with Hedging parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_hedging, stat = iterative_mle_state_estimate(data, dilution=0.5, beta=.61)\n",
    "rho = est_hedging.estimate.state_point_est\n",
    "print(np.around(rho, decimals=4))\n",
    "print('Purity = ', np.trace(rho @ rho))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project an unphysical state to the closest physical state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_qcvv.tomography import project_density_matrix\n",
    "rho_unphys = np.array([[1.0, 0], [0, -0.75]])\n",
    "rho_phys = project_density_matrix(rho_unphys)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "hinton(rho_unphys, ax=ax1)\n",
    "hinton(rho_phys, ax=ax2)\n",
    "ax1.set_title('Unphysical')\n",
    "ax2.set_title('Physical projection')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the wizard method. Example from fig 1 of maximum likelihood minimum effort \n",
    "# https://doi.org/10.1103/PhysRevLett.108.070502\n",
    "\n",
    "eigs = np.diag(np.array(list(reversed([3.0/5, 1.0/2, 7.0/20, 1.0/10, -11.0/20]))))\n",
    "phys = project_density_matrix(eigs)\n",
    "np.allclose(phys, np.diag([0, 0, 1.0/5, 7.0/20, 9.0/20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Bootstrap for functionals of the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forest_qcvv.distance_measures as dm\n",
    "from forest_qcvv.tomography import estimate_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mle_estimator(data):\n",
    "    return iterative_mle_state_estimate(data, dilution=0.5, entropy_penalty=0.0, beta=0.0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle_est = estimate_variance(data, my_mle_estimator, dm.purity, n_resamples=40, project_to_physical=True)\n",
    "lin_inv_est = estimate_variance(data, linear_inv_state_estimate, dm.purity, n_resamples=40, project_to_physical=True)\n",
    "print(mle_est)\n",
    "print(lin_inv_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fidelity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle_est = estimate_variance(data, my_mle_estimator, dm.fidelity, target_state=rho_true, n_resamples=40, project_to_physical=True)\n",
    "lin_inv_est = estimate_variance(data, linear_inv_state_estimate, dm.fidelity, target_state=rho_true, n_resamples=40, project_to_physical=True)\n",
    "print(mle_est)\n",
    "print(lin_inv_est)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
