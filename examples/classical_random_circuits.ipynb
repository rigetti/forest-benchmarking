{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Random Circuits\n",
    "\n",
    "Here we use classical circuits to get a handle on error rates.\n",
    "\n",
    "This module that generates classical random circuits (that are not universal) on a graph which represents the QPU or QVM lattice. The basic idea is it will compute error rates of circuits as a function of depth and width.\n",
    "\n",
    "The `width` of the circuit is the number of connected vertices on a particular subgraph.\n",
    "\n",
    "The `depth` is defined in an unusual way. We consider a \"depth 1\" circuit to be a round of X gates randomly applied or not to a particular vertex AND a round of CNOTs randomly applied or not to each edge of the graph.\n",
    "\n",
    "The circuit can also be executed in the X basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.spatial.distance import hamming\n",
    "import scipy.interpolate\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pyquil.api import get_qc, QuantumComputer\n",
    "from pyquil.gates import CNOT, CCNOT, X, I, H, CZ, MEASURE, RESET\n",
    "from pyquil.quilbase import Pragma\n",
    "\n",
    "from forest_benchmarking.classical_random_circuits import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to run on a \"real lattice\"\n",
    "#from pyquil import *\n",
    "#list_quantum_computers()\n",
    "qc_perfect = get_qc(\"Aspen-1-15Q-A\", as_qvm=True, noisy=False)\n",
    "qc_noisy = get_qc(\"Aspen-1-15Q-A\", as_qvm=True, noisy=True)\n",
    "print(qc_perfect.name)\n",
    "print(qc_noisy.name)\n",
    "\n",
    "qc_perfect = get_qc(\"9q-square-qvm\", as_qvm=True, noisy=False)\n",
    "qc_noisy = get_qc(\"9q-square-qvm\", as_qvm=True, noisy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(qc_perfect.qubit_topology(),with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the distribution of sublattice widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = qc_perfect.qubit_topology()\n",
    "len(qc_perfect.qubit_topology())\n",
    "# distribution of graph lengths\n",
    "disty = []\n",
    "for gdx in range(1,len(G.nodes)+1):\n",
    "    listg = generate_connected_subgraphs(G,gdx)\n",
    "    disty.append(len(listg))\n",
    "\n",
    "cir_wid = list(range(1,len(G.nodes)+1))\n",
    "plt.bar(cir_wid, disty, width=0.61, align='center')\n",
    "plt.xticks(cir_wid)\n",
    "plt.xlabel('sublattice / circuit width')\n",
    "plt.ylabel('Frequency of Occurence')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.title('Distribution of sublattice widths')\n",
    "disty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with these parameters the cell below takes about 2 minutes\n",
    "num_shots_per_circuit = 100\n",
    "num_rand_subgraphs = 6\n",
    "circuit_depth = 8\n",
    "circuit_width = 6 #max = len(G.nodes)\n",
    "in_x_basis = False\n",
    "use_active_reset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "data = get_random_classical_circuit_results(qc_perfect, qc_noisy, circuit_depth, circuit_width, num_rand_subgraphs, num_shots_per_circuit)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now put the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a particular depth and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = 2\n",
    "wid = 2\n",
    "\n",
    "distz = get_hamming_dist(df, dep, wid)\n",
    "averaged_distr = distz['hamming_dist'][0]\n",
    "rand_ans_distr = hamming_dist_rand(wid,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = np.arange(0, len(averaged_distr))\n",
    "plt.bar(x_labels, averaged_distr, width=0.61, align='center')\n",
    "plt.bar(x_labels, rand_ans_distr, width=0.31, align='center')\n",
    "plt.xticks(x_labels)\n",
    "plt.xlabel('Hamming Weight of Error')\n",
    "plt.ylabel('Relative Frequency of Occurence')\n",
    "plt.ylim([0,1])\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.legend(['data','random'])\n",
    "plt.title('Depth = {}, Width = {}'.format(dep,wid))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For a particular width plot all depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wid = 4\n",
    "hdis = get_hamming_dists_fn_depth(df, wid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hdx in range(0, len(hdis)):\n",
    "    averaged_distr = hdis.iloc[hdx]['hamming_dist']\n",
    "    dep = hdis.iloc[hdx]['depth']\n",
    "    rand_ans_distr = hamming_dist_rand(wid,0)\n",
    "    x_labels = np.arange(0, len(averaged_distr))\n",
    "    plt.subplot(1,len(hdis),hdx+1)\n",
    "    plt.bar(x_labels, averaged_distr, width=0.61, align='center')\n",
    "    plt.bar(x_labels, rand_ans_distr, width=0.31, align='center')\n",
    "    plt.xticks(x_labels)\n",
    "    plt.xlabel('Hamming Weight of Error')\n",
    "    plt.ylabel('Relative Frequency of Occurence')\n",
    "    plt.ylim([0,1])\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.legend(['data','random'])\n",
    "    plt.title('Depth = {}, Width = {}'.format(dep,wid))\n",
    "plt.subplots_adjust(bottom=0.1, right=3.2, top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can study the sucess probablity, i.e. the zero hamming weight entry above as a function of depth. We first need to extract the data fron the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bit_flips_allowed_from_answer = int(basement_function(np.log2(wid)-1))\n",
    "\n",
    "pcheck = []\n",
    "pcheck_rand = []\n",
    "depth_vec = []\n",
    "pcheck_log_errors = []\n",
    "rand_pcheck_log_errors = []\n",
    "\n",
    "for hdx in range(0, len(hdis)):\n",
    "    averaged_distr = hdis.iloc[hdx]['hamming_dist']\n",
    "    # probablity of getting the correct answer\n",
    "    pcheck.append(averaged_distr[0])\n",
    "    rand_ans_distr = hamming_dist_rand(wid,0)\n",
    "    # probablity of getting the correct by randomly guessing\n",
    "    pcheck_rand.append(rand_ans_distr[0])\n",
    "    # error when you allow for a logarithmic number of bit flips from the true answer\n",
    "    pcheck_log_errors.append(sum([averaged_distr[idx] for idx in range(0,num_bit_flips_allowed_from_answer+1)]))\n",
    "    rand_pcheck_log_errors.append(sum([rand_ans_distr[idx] for idx in range(0,num_bit_flips_allowed_from_answer+1)]))\n",
    "    dep = hdis.iloc[hdx]['depth']\n",
    "    depth_vec.append(dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will plot the sucess probablity of a circuit with a certain width as a function of depth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(depth_vec,pcheck,label='Sucess Probablity')\n",
    "plt.plot(depth_vec,pcheck_rand,label='random guess')\n",
    "plt.ylim([0,1.05])\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Pr(success)')\n",
    "plt.title('Pr(success) vs Depth for Width = {}'.format(wid))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we allow a logarithmic number of bits to flip from the correct answer and call all such instances \"success\". E.g.\n",
    "\n",
    "The logarithmic number of bits that we allow to flip is defined by the \"basement\" of \n",
    "\n",
    "$\\log_2 ({\\rm number\\ of\\ bits}) -1$\n",
    "\n",
    "where the basement of a number is ${\\rm basement(number)} = 0$ if number$<=0$ and ${\\rm basement(number)} = {\\rm floor (number)}$.\n",
    "\n",
    "\n",
    "Supose we have a circuit of width 4, this means correct string has four bits, e.g. 1010. Then a logarithmic number of flips is $\\log_2(4)-1 = 1$.\n",
    "\n",
    "So any string with hamming weight zero or one counts as a success.\n",
    "\n",
    "Such error metrics might be important in noisy near term algorithms where getting the exact answer is not vital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(depth_vec,pcheck_log_errors,label='Sucess Probablity + log errors')\n",
    "plt.plot(depth_vec,rand_pcheck_log_errors,label='random guess + log errors')\n",
    "plt.ylim([0,1.05])\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Pr(success+log errors)')\n",
    "plt.title('Pr(success+log errors) vs Depth for Width = {}'.format(wid))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot depth = width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = min([max(df['depth']),max(df['width'])])\n",
    "\n",
    "for idx in range(1,max_idx+1):\n",
    "    hdis = get_hamming_dist(df, idx, idx)\n",
    "    averaged_distr = hdis['hamming_dist'][0]\n",
    "    dep = hdis['depth'][0]\n",
    "    wid = hdis['width'][0]\n",
    "    rand_ans_distr = hamming_dist_rand(idx,0)\n",
    "    x_labels = np.arange(0, len(averaged_distr))\n",
    "    plt.subplot(1,max_idx,idx)\n",
    "    plt.bar(x_labels, averaged_distr, width=0.61, align='center')\n",
    "    plt.bar(x_labels, rand_ans_distr, width=0.31, align='center')\n",
    "    plt.xticks(x_labels)\n",
    "    plt.xlabel('Hamming Weight of Error')\n",
    "    plt.ylabel('Relative Frequency of Occurence')\n",
    "    plt.ylim([0,1])\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.legend(['data','random'])\n",
    "    plt.title('Depth = {}, Width = {}'.format(dep,wid))\n",
    "plt.subplots_adjust(bottom=0.1, right=3.2, top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot success probablity landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just the success probablity as a function of depth and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.vstack((df['depth'].values, df['width'].values)).T\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['hamming_dist'][0] returns the array\n",
    "# df['hamming_dist'][0][0] returns the first element of the array\n",
    "values = np.asarray([df['hamming_dist'][idx][0] for idx in df.index])\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_width = [hamming_dist_rand(idx, 0)[0] for idx in range(1,circuit_width+1)]\n",
    "rand_width\n",
    "\n",
    "values_rand = np.asarray([item for sublist in [rand_width for ddx in range(1,circuit_depth+1)] for item in sublist])\n",
    "values_rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy, zz = interpolate_2d_landscape(points, values)\n",
    "\n",
    "ax = plt.gca()\n",
    "img = ax.imshow(zz, interpolation='none',\n",
    "                extent=(xx[0, 0], xx[0, -1], yy[0, 0], yy[-1, 0]),\n",
    "                cmap='viridis', origin='lowerleft', norm=plt.Normalize(None, None))\n",
    "plt.colorbar(img, ax=ax)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Width')\n",
    "plt.title('Success Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(points.shape)\n",
    "xx, yy, zz = interpolate_2d_landscape(points, values_rand)\n",
    "\n",
    "ax = plt.gca()\n",
    "img = ax.imshow(zz, interpolation='none',\n",
    "                extent=(xx[0, 0], xx[0, -1], yy[0, 0], yy[-1, 0]),\n",
    "                cmap='viridis', origin='lowerleft', norm=plt.Normalize(None, None))\n",
    "plt.colorbar(img, ax=ax)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Width')\n",
    "plt.title('Success Probability for Random guess')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
